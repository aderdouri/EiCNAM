{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "authorship_tag": "ABX9TyNoH3moyBRDYpgrX84KIfxZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aderdouri/EiCNAM/blob/master/Tutorials/Notebooks/adjoint_mode_graph.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Heston PDE Residual\n",
        "def heston_pde_residual(model, s, v, t, kappa, theta, sigma, rho, r):\n",
        "    \"\"\"\n",
        "    Compute the residual of the Heston PDE.\n",
        "    \"\"\"\n",
        "    s.requires_grad = True\n",
        "    v.requires_grad = True\n",
        "    t.requires_grad = True\n",
        "\n",
        "    # Forward pass\n",
        "    V = model(torch.cat((s, v, t), dim=1))\n",
        "\n",
        "    # Gradients\n",
        "    V_t = torch.autograd.grad(V, t, grad_outputs=torch.ones_like(V), create_graph=True)[0]\n",
        "    V_s = torch.autograd.grad(V, s, grad_outputs=torch.ones_like(V), create_graph=True)[0]\n",
        "    V_v = torch.autograd.grad(V, v, grad_outputs=torch.ones_like(V), create_graph=True)[0]\n",
        "    V_ss = torch.autograd.grad(V_s, s, grad_outputs=torch.ones_like(V_s), create_graph=True)[0]\n",
        "    V_vv = torch.autograd.grad(V_v, v, grad_outputs=torch.ones_like(V_v), create_graph=True)[0]\n",
        "    V_sv = torch.autograd.grad(V_s, v, grad_outputs=torch.ones_like(V_s), create_graph=True)[0]\n",
        "\n",
        "    # Heston PDE\n",
        "    term1 = V_t\n",
        "    term2 = 0.5 * v * s**2 * V_ss\n",
        "    term3 = rho * sigma * v * s * V_sv\n",
        "    term4 = 0.5 * sigma**2 * v * V_vv\n",
        "    term5 = r * s * V_s\n",
        "    term6 = kappa * (theta - v) * V_v\n",
        "    term7 = -r * V\n",
        "\n",
        "    residual = term1 + term2 + term3 + term4 + term5 + term6 + term7\n",
        "    return residual\n",
        "\n",
        "# Define the PINN model\n",
        "class PINN(nn.Module):\n",
        "    def __init__(self, hidden_dim=50, num_layers=4):\n",
        "        super(PINN, self).__init__()\n",
        "        layers = []\n",
        "        layers.append(nn.Linear(3, hidden_dim))  # Input: (S, v, t)\n",
        "        layers.append(nn.Tanh())\n",
        "        for _ in range(num_layers - 1):\n",
        "            layers.append(nn.Linear(hidden_dim, hidden_dim))\n",
        "            layers.append(nn.Tanh())\n",
        "        layers.append(nn.Linear(hidden_dim, 1))  # Output: V(S, v, t)\n",
        "        self.network = nn.Sequential(*layers)\n",
        "\n",
        "        # Trainable parameters\n",
        "        self.kappa = nn.Parameter(torch.tensor(2.0, requires_grad=True, dtype=torch.float32))\n",
        "        self.theta = nn.Parameter(torch.tensor(0.2, requires_grad=True, dtype=torch.float32))\n",
        "        self.sigma = nn.Parameter(torch.tensor(0.3, requires_grad=True, dtype=torch.float32))\n",
        "        self.rho = nn.Parameter(torch.tensor(-0.7, requires_grad=True, dtype=torch.float32))\n",
        "        self.r = nn.Parameter(torch.tensor(0.05, requires_grad=True, dtype=torch.float32))\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.network(x)\n",
        "\n",
        "# Loss Function\n",
        "def compute_loss(model, s, v, t, observed_s, observed_v, observed_t, observed_prices):\n",
        "    # Extract trainable parameters\n",
        "    kappa, theta, sigma, rho, r = model.kappa, model.theta, model.sigma, model.rho, model.r\n",
        "\n",
        "    # PDE Residual Loss\n",
        "    residual = heston_pde_residual(model, s, v, t, kappa, theta, sigma, rho, r)\n",
        "    pde_loss = torch.mean(residual**2)\n",
        "\n",
        "    # Observed Data Loss\n",
        "    observed_inputs = torch.cat((observed_s, observed_v, observed_t), dim=1)\n",
        "    observed_preds = model(observed_inputs)\n",
        "    data_loss = torch.mean((observed_preds - observed_prices)**2)\n",
        "\n",
        "    return pde_loss + data_loss\n",
        "\n",
        "# Training Function\n",
        "def train_pinn(model, s, v, t, observed_s, observed_v, observed_t, observed_prices, epochs=1000, lr=1e-3):\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        optimizer.zero_grad()\n",
        "        loss = compute_loss(model, s, v, t, observed_s, observed_v, observed_t, observed_prices)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(f\"Epoch {epoch}, Loss: {loss.item():.6f}, kappa: {model.kappa.item():.6f}, \"\n",
        "                  f\"theta: {model.theta.item():.6f}, sigma: {model.sigma.item():.6f}, \"\n",
        "                  f\"rho: {model.rho.item():.6f}, r: {model.r.item():.6f}\")\n",
        "\n",
        "# Example Usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Observed data (mock data for simplicity)\n",
        "    observed_s = torch.tensor([[50.0], [100.0], [150.0]])\n",
        "    observed_v = torch.tensor([[0.2], [0.2], [0.2]])\n",
        "    observed_t = torch.tensor([[0.5], [0.5], [0.5]])\n",
        "    observed_prices = torch.tensor([[10.0], [15.0], [20.0]])\n",
        "\n",
        "    # Collocation points for PDE residual computation\n",
        "    s = torch.rand(100, 1) * 200  # Stock prices in [0, 200]\n",
        "    v = torch.rand(100, 1) * 1.0  # Variance in [0, 1]\n",
        "    t = torch.rand(100, 1) * 1.0  # Time in [0, 1]\n",
        "\n",
        "    # Initialize and train the model\n",
        "    model = PINN(hidden_dim=50, num_layers=4)\n",
        "    train_pinn(model, s, v, t, observed_s, observed_v, observed_t, observed_prices)\n",
        "\n",
        "    # Validate the model\n",
        "    s_test = torch.linspace(10, 200, 100).view(-1, 1)\n",
        "    v_test = torch.full_like(s_test, 0.2)\n",
        "    t_test = torch.full_like(s_test, 0.5)\n",
        "    inputs = torch.cat((s_test, v_test, t_test), dim=1)\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    # Plot the results\n",
        "    plt.plot(s_test.detach().numpy(), predictions.detach().numpy(), label=\"PINN Predictions\")\n",
        "    plt.scatter(observed_s.detach().numpy(), observed_prices.detach().numpy(), color='red', label=\"Observed Data\")\n",
        "    plt.xlabel(\"Stock Price (S)\")\n",
        "    plt.ylabel(\"Option Price (V)\")\n",
        "    plt.legend()\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "id": "HHh3-6_UZ_60"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "OD3G-rCbSKMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "pVrg7vNnaOgm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "0.01/np.pi"
      ],
      "metadata": {
        "id": "0HvbEW9yaRaG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install deepxde"
      ],
      "metadata": {
        "id": "5reX6EhKaVn1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepxde as dde\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Define the Black-Scholes PDE\n",
        "def pde(x, y):\n",
        "    V = y\n",
        "    dV_dt = dde.grad.jacobian(y, x, i=0, j=0)  # ∂V/∂t\n",
        "    dV_dS = dde.grad.jacobian(y, x, i=0, j=1)  # ∂V/∂S\n",
        "    d2V_dS2 = dde.grad.hessian(y, x, component=0, i=1, j=1)  # ∂²V/∂S²\n",
        "    sigma = 0.2\n",
        "    r = 0.05\n",
        "    return dV_dt + 0.5 * sigma**2 * x[:, 1:2]**2 * d2V_dS2 + r * x[:, 1:2] * dV_dS - r * V\n",
        "\n",
        "# Define the domain and boundary conditions\n",
        "geom = dde.geometry.Interval(0, 1)  # Stock price interval [0, 1]\n",
        "timedomain = dde.geometry.TimeDomain(0, 1)  # Time interval [0, 1]\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)  # Space-time domain\n",
        "\n",
        "# Initial condition: V(S, 0) = max(S - K, 0) for a call option\n",
        "def initial_condition(x):\n",
        "    K = 0.5\n",
        "    return np.maximum(x[:, 1:2] - K, 0)\n",
        "\n",
        "# Boundary condition: V(0, t) = 0 and V(S, t) -> S as S -> infinity\n",
        "def boundary_left(x, on_boundary):\n",
        "    return on_boundary and np.isclose(x[0], 0)  # Left boundary (S=0)\n",
        "\n",
        "def boundary_right(x, on_boundary):\n",
        "    return on_boundary and np.isclose(x[0], 1)  # Right boundary (S=1)\n",
        "\n",
        "bc_left = dde.DirichletBC(geomtime, lambda x: 0, boundary_left)  # V(0, t) = 0\n",
        "bc_right = dde.DirichletBC(geomtime, lambda x: x[:, 1:2], boundary_right)  # V(S, t) -> S as S → infinity\n",
        "\n",
        "# Define the data for the PDE\n",
        "data = dde.data.TimePDE(\n",
        "    geomtime,\n",
        "    pde,\n",
        "    [bc_left, bc_right],\n",
        "    num_domain=2540,\n",
        "    num_boundary=80,\n",
        "    num_initial=160,\n",
        "    anchors=None,\n",
        "    solution=initial_condition,  # Solution for the initial condition\n",
        ")\n",
        "\n",
        "# Define the neural network\n",
        "net = dde.maps.FNN([2] + [50] * 3 + [1], \"tanh\", \"Glorot uniform\")\n",
        "\n",
        "# Define the model\n",
        "model = dde.Model(data, net)\n",
        "\n",
        "# Train the model\n",
        "model.compile(\"adam\", lr=1e-3)\n",
        "losshistory, train_state = model.train(epochs=10000)"
      ],
      "metadata": {
        "id": "jTQSLqwa9Tg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Analytical Black-Scholes solution for comparison\n",
        "def black_scholes_call(S, K, T, r, sigma):\n",
        "    # Ensure valid inputs\n",
        "    S = np.maximum(S, 1e-8)  # Prevent S = 0\n",
        "    K = np.maximum(K, 1e-8)  # Prevent K = 0\n",
        "    T = np.maximum(T, 1e-8)  # Prevent T = 0\n",
        "    sigma = np.maximum(sigma, 1e-8)  # Prevent sigma = 0\n",
        "\n",
        "    # Black-Scholes formula\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "\n",
        "\n",
        "# Generate test data\n",
        "S_test = np.linspace(0, 1, 100)\n",
        "T_test = np.linspace(0, 1, 100)\n",
        "S_test, T_test = np.meshgrid(S_test, T_test)\n",
        "X_test = np.vstack((T_test.flatten(), S_test.flatten())).T\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the analytical solution\n",
        "K = 0.5\n",
        "r = 0.05\n",
        "sigma = 0.2\n",
        "y_true = black_scholes_call(S_test.flatten(), K, T_test.flatten(), r, sigma)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(S_test.flatten(), y_true, label=\"Analytical Solution\", linestyle='--')\n",
        "plt.scatter(S_test.flatten(), y_pred, label=\"Predicted Solution\", color='r', s=10)\n",
        "plt.xlabel(\"Stock Price\")\n",
        "plt.ylabel(\"Option Price\")\n",
        "plt.legend()\n",
        "plt.title(\"Comparison of Predicted vs Analytical Black-Scholes Option Prices\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WpczWIWGBffd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepxde as dde\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Define the Black-Scholes PDE\n",
        "def pde(x, y):\n",
        "    V = y\n",
        "    dV_dt = dde.grad.jacobian(y, x, i=0, j=0)  # ∂V/∂t\n",
        "    dV_dS = dde.grad.jacobian(y, x, i=0, j=1)  # ∂V/∂S\n",
        "    d2V_dS2 = dde.grad.hessian(y, x, component=0, i=1, j=1)  # ∂²V/∂S²\n",
        "    sigma = 0.2  # Volatility\n",
        "    r = 0.05     # Risk-free interest rate\n",
        "    return dV_dt + 0.5 * sigma**2 * x[:, 1:2]**2 * d2V_dS2 + r * x[:, 1:2] * dV_dS - r * V\n",
        "\n",
        "# Define the domain and geometry\n",
        "geom = dde.geometry.Interval(0, 1)  # Stock price interval [0, 1]\n",
        "timedomain = dde.geometry.TimeDomain(0, 1)  # Time interval [0, 1]\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)  # Space-time domain\n",
        "\n",
        "# Initial condition: V(S, 0) = max(S - K, 0) for a call option\n",
        "def initial_condition(x):\n",
        "    K = 0.5\n",
        "    return np.maximum(x[:, 1:2] - K, 0)\n",
        "\n",
        "# Boundary conditions: V(0, t) = 0 and V(S, t) → S as S → ∞\n",
        "def boundary_left(x, on_boundary):\n",
        "    return on_boundary and np.isclose(x[0], 0)  # Left boundary (S = 0)\n",
        "\n",
        "def boundary_right(x, on_boundary):\n",
        "    return on_boundary and np.isclose(x[0], 1)  # Right boundary (S = 1)\n",
        "\n",
        "bc_left = dde.DirichletBC(geomtime, lambda x: 0, boundary_left)  # V(0, t) = 0\n",
        "bc_right = dde.DirichletBC(geomtime, lambda x: x[:, 1:2], boundary_right)  # V(S, t) → S\n",
        "\n",
        "# Define the data for the PDE\n",
        "data = dde.data.TimePDE(\n",
        "    geomtime,\n",
        "    pde,\n",
        "    [bc_left, bc_right],\n",
        "    num_domain=2540,\n",
        "    num_boundary=80,\n",
        "    num_initial=160,\n",
        "    solution=initial_condition,  # Solution for the initial condition\n",
        ")\n",
        "\n",
        "# Define the neural network\n",
        "net = dde.maps.FNN([2] + [50] * 3 + [1], \"tanh\", \"Glorot uniform\")\n",
        "\n",
        "# Define the model\n",
        "model = dde.Model(data, net)\n",
        "\n",
        "# Train the model with Adam optimizer\n",
        "model.compile(\"adam\", lr=1e-3)\n",
        "losshistory, train_state = model.train(epochs=5000)\n",
        "\n",
        "# Fine-tune with LBFGS optimizer\n",
        "model.compile(\"lbfgs\", lr=1e-3) # Added a learning rate\n",
        "losshistory, train_state = model.train()\n",
        "\n",
        "# Analytical Black-Scholes solution for comparison\n",
        "def black_scholes_call(S, K, T, r, sigma):\n",
        "    S = np.maximum(S, 1e-8)  # Prevent divide-by-zero issues\n",
        "    K = np.maximum(K, 1e-8)\n",
        "    T = np.maximum(T, 1e-8)\n",
        "    sigma = np.maximum(sigma, 1e-8)\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "\n",
        "# Generate test data\n",
        "S_test = np.linspace(0, 1, 100)  # Normalized stock prices\n",
        "T_test = np.linspace(0, 1, 100)  # Normalized times\n",
        "S_test, T_test = np.meshgrid(S_test, T_test)\n",
        "X_test = np.vstack((T_test.flatten(), S_test.flatten())).T\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the analytical solution\n",
        "K = 0.5\n",
        "r = 0.05\n",
        "sigma = 0.2\n",
        "y_true = black_scholes_call(S_test.flatten(), K, T_test.flatten(), r, sigma)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(S_test.flatten(), y_true, label=\"Analytical Solution\", linestyle=\"--\", color=\"blue\")\n",
        "plt.scatter(S_test.flatten(), y_pred, label=\"Predicted Solution\", color=\"red\", s=10)\n",
        "plt.xlabel(\"Stock Price (S)\")\n",
        "plt.ylabel(\"Option Price (V)\")\n",
        "plt.legend()\n",
        "plt.title(\"Comparison of Predicted vs Analytical Black-Scholes Option Prices\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "9M2nxqInAazt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import deepxde as dde\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Define the Black-Scholes PDE\n",
        "def pde(x, y):\n",
        "    V = y\n",
        "    dV_dt = dde.grad.jacobian(y, x, i=0, j=0)  # ∂V/∂t\n",
        "    dV_dS = dde.grad.jacobian(y, x, i=0, j=1)  # ∂V/∂S\n",
        "    d2V_dS2 = dde.grad.hessian(y, x, component=0, i=1, j=1)  # ∂²V/∂S²\n",
        "    sigma = 0.2  # Volatility\n",
        "    r = 0.05     # Risk-free interest rate\n",
        "    return dV_dt + 0.5 * sigma**2 * x[:, 1:2]**2 * d2V_dS2 + r * x[:, 1:2] * dV_dS - r * V\n",
        "\n",
        "# Define the domain and geometry\n",
        "geom = dde.geometry.Interval(0, 1)  # Stock price interval [0, 1]\n",
        "timedomain = dde.geometry.TimeDomain(0, 1)  # Time interval [0, 1]\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)  # Space-time domain\n",
        "\n",
        "# Initial condition: V(S, 0) = max(S - K, 0) for a call option\n",
        "def initial_condition(x):\n",
        "    K = 0.5\n",
        "    return np.maximum(x[:, 1:2] - K, 0)\n",
        "\n",
        "# Boundary conditions: V(0, t) = 0 and V(S, t) → S as S → ∞\n",
        "def boundary_left(x, on_boundary):\n",
        "    return on_boundary and np.isclose(x[0], 0)  # Left boundary (S = 0)\n",
        "\n",
        "def boundary_right(x, on_boundary):\n",
        "    return on_boundary and np.isclose(x[0], 1)  # Right boundary (S = 1)\n",
        "\n",
        "bc_left = dde.DirichletBC(geomtime, lambda x: 0, boundary_left)  # V(0, t) = 0\n",
        "bc_right = dde.DirichletBC(geomtime, lambda x: x[:, 1:2], boundary_right)  # V(S, t) → S\n",
        "\n",
        "# Define the data for the PDE\n",
        "data = dde.data.TimePDE(\n",
        "    geomtime,\n",
        "    pde,\n",
        "    [bc_left, bc_right],\n",
        "    num_domain=2540,\n",
        "    num_boundary=80,\n",
        "    num_initial=160,\n",
        "    solution=initial_condition,  # Solution for the initial condition\n",
        ")\n",
        "\n",
        "# Define the neural network\n",
        "net = dde.maps.FNN([2] + [50] * 3 + [1], \"tanh\", \"Glorot uniform\")\n",
        "\n",
        "# Define the model\n",
        "model = dde.Model(data, net)\n",
        "\n",
        "# Train the model with Adam optimizer\n",
        "model.compile(\"adam\", lr=1e-3)\n",
        "losshistory, train_state = model.train(epochs=5000)\n",
        "\n",
        "# # Fine-tune with LBFGS optimizer - Removed the problematic lines\n",
        "model.compile(\"L-BFGS\") # Added a learning rate\n",
        "# losshistory, train_state = model.train()\n",
        "\n",
        "# Analytical Black-Scholes solution for comparison\n",
        "def black_scholes_call(S, K, T, r, sigma):\n",
        "    S = np.maximum(S, 1e-8)  # Prevent divide-by-zero issues\n",
        "    K = np.maximum(K, 1e-8)\n",
        "    T = np.maximum(T, 1e-8)\n",
        "    sigma = np.maximum(sigma, 1e-8)\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "    return S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "\n",
        "# Generate test data\n",
        "S_test = np.linspace(0, 1, 100)  # Normalized stock prices\n",
        "T_test = np.linspace(0, 1, 100)  # Normalized times\n",
        "S_test, T_test = np.meshgrid(S_test, T_test)\n",
        "X_test = np.vstack((T_test.flatten(), S_test.flatten())).T\n",
        "\n",
        "# Predict using the trained model\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Calculate the analytical solution\n",
        "K = 0.5\n",
        "r = 0.05\n",
        "sigma = 0.2\n",
        "y_true = black_scholes_call(S_test.flatten(), K, T_test.flatten(), r, sigma)\n",
        "\n",
        "# Plot the results\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(S_test.flatten(), y_true, label=\"Analytical Solution\", linestyle=\"--\", color=\"blue\")\n",
        "plt.scatter(S_test.flatten(), y_pred, label=\"Predicted Solution\", color=\"red\", s=10)\n",
        "plt.xlabel(\"Stock Price (S)\")\n",
        "plt.ylabel(\"Option Price (V)\")\n",
        "plt.legend()\n",
        "plt.title(\"Comparison of Predicted vs Analytical Black-Scholes Option Prices\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "D9J8K9XcKKXX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"Backend supported: tensorflow.compat.v1, tensorflow, pytorch, paddle\"\"\"\n",
        "import deepxde as dde\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def heat_eq_exact_solution(x, t):\n",
        "    \"\"\"Returns the exact solution for a given x and t (for sinusoidal initial conditions).\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    x : np.ndarray\n",
        "    t : np.ndarray\n",
        "    \"\"\"\n",
        "    return np.exp(-(n**2 * np.pi**2 * a * t) / (L**2)) * np.sin(n * np.pi * x / L)\n",
        "\n",
        "\n",
        "def gen_exact_solution():\n",
        "    \"\"\"Generates exact solution for the heat equation for the given values of x and t.\"\"\"\n",
        "    # Number of points in each dimension:\n",
        "    x_dim, t_dim = (256, 201)\n",
        "\n",
        "    # Bounds of 'x' and 't':\n",
        "    x_min, t_min = (0, 0.0)\n",
        "    x_max, t_max = (L, 1.0)\n",
        "\n",
        "    # Create tensors:\n",
        "    t = np.linspace(t_min, t_max, num=t_dim).reshape(t_dim, 1)\n",
        "    x = np.linspace(x_min, x_max, num=x_dim).reshape(x_dim, 1)\n",
        "    usol = np.zeros((x_dim, t_dim)).reshape(x_dim, t_dim)\n",
        "\n",
        "    # Obtain the value of the exact solution for each generated point:\n",
        "    for i in range(x_dim):\n",
        "        for j in range(t_dim):\n",
        "            usol[i][j] = heat_eq_exact_solution(x[i], t[j])\n",
        "\n",
        "    # Save solution:\n",
        "    np.savez(\"heat_eq_data\", x=x, t=t, usol=usol)\n",
        "\n",
        "\n",
        "def gen_testdata():\n",
        "    \"\"\"Import and preprocess the dataset with the exact solution.\"\"\"\n",
        "    # Load the data:\n",
        "    data = np.load(\"heat_eq_data.npz\")\n",
        "    # Obtain the values for t, x, and the excat solution:\n",
        "    t, x, exact = data[\"t\"], data[\"x\"], data[\"usol\"].T\n",
        "    # Process the data and flatten it out (like labels and features):\n",
        "    xx, tt = np.meshgrid(x, t)\n",
        "    X = np.vstack((np.ravel(xx), np.ravel(tt))).T\n",
        "    y = exact.flatten()[:, None]\n",
        "    return X, y\n",
        "\n",
        "\n",
        "# Problem parameters:\n",
        "a = 0.4  # Thermal diffusivity\n",
        "L = 1  # Length of the bar\n",
        "n = 1  # Frequency of the sinusoidal initial conditions\n",
        "\n",
        "# Generate a dataset with the exact solution (if you dont have one):\n",
        "gen_exact_solution()\n",
        "\n",
        "\n",
        "def pde(x, y):\n",
        "    \"\"\"Expresses the PDE residual of the heat equation.\"\"\"\n",
        "    dy_t = dde.grad.jacobian(y, x, i=0, j=1)\n",
        "    dy_xx = dde.grad.hessian(y, x, i=0, j=0)\n",
        "    return dy_t - a * dy_xx\n",
        "\n",
        "\n",
        "# Computational geometry:\n",
        "geom = dde.geometry.Interval(0, L)\n",
        "timedomain = dde.geometry.TimeDomain(0, 1)\n",
        "geomtime = dde.geometry.GeometryXTime(geom, timedomain)\n",
        "\n",
        "# Initial and boundary conditions:\n",
        "bc = dde.icbc.DirichletBC(geomtime, lambda x: 0, lambda _, on_boundary: on_boundary)\n",
        "ic = dde.icbc.IC(\n",
        "    geomtime,\n",
        "    lambda x: np.sin(n * np.pi * x[:, 0:1] / L),\n",
        "    lambda _, on_initial: on_initial,\n",
        ")\n",
        "\n",
        "# Define the PDE problem and configurations of the network:\n",
        "data = dde.data.TimePDE(\n",
        "    geomtime,\n",
        "    pde,\n",
        "    [bc, ic],\n",
        "    num_domain=2540,\n",
        "    num_boundary=80,\n",
        "    num_initial=160,\n",
        "    num_test=2540,\n",
        ")\n",
        "net = dde.nn.FNN([2] + [20] * 3 + [1], \"tanh\", \"Glorot normal\")\n",
        "model = dde.Model(data, net)\n",
        "\n",
        "# Build and train the model:\n",
        "model.compile(\"adam\", lr=1e-3)\n",
        "model.train(iterations=20000)\n",
        "model.compile(\"L-BFGS\")\n",
        "losshistory, train_state = model.train()\n",
        "\n",
        "# Plot/print the results\n",
        "dde.saveplot(losshistory, train_state, issave=True, isplot=True)\n",
        "X, y_true = gen_testdata()\n",
        "y_pred = model.predict(X)\n",
        "f = model.predict(X, operator=pde)\n",
        "print(\"Mean residual:\", np.mean(np.absolute(f)))\n",
        "print(\"L2 relative error:\", dde.metrics.l2_relative_error(y_true, y_pred))\n",
        "#np.savetxt(\"test.dat\", np.hstack((X, y_true, y_pred)))"
      ],
      "metadata": {
        "id": "Y9fW2QtYL_ZU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the test dataset (observed values)\n",
        "X, y_true = gen_testdata()  # X: (t, x), y_true: observed solution\n",
        "y_pred = model.predict(X)  # Predicted solution\n",
        "\n",
        "# Print the first few observed and predicted values\n",
        "print(\"Observed (True) vs Predicted:\")\n",
        "for i in range(10):  # Print first 10 values\n",
        "    print(f\"Observed: {y_true[i][0]:.6f}, Predicted: {y_pred[i][0]:.6f}\")\n",
        "\n",
        "# Visualize Observed vs Predicted\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(y_true, label=\"Observed (True)\", linestyle=\"--\", color=\"blue\", alpha=1)\n",
        "plt.plot(y_pred, label=\"Predicted\", linestyle=\"-\", color=\"red\", alpha=0.7)\n",
        "plt.xlabel(\"Index\")\n",
        "plt.ylabel(\"Solution\")\n",
        "plt.title(\"Comparison of Observed vs Predicted Values\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "u33_u70yaawo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "FwknMU0YblZo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install -y graphviz libgraphviz-dev"
      ],
      "metadata": {
        "id": "_8MFdJxQj61M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pygraphviz"
      ],
      "metadata": {
        "id": "wfbtAofGkYWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install networkx"
      ],
      "metadata": {
        "id": "WZEgw3lojE0i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the computational graph for the Black formula for a call option\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Inputs\n",
        "G.add_node(\"F\", label=\"F (Forward Price)\", color=\"lightgray\")  # Forward price\n",
        "G.add_node(\"K\", label=\"K (Strike Price)\", color=\"lightgray\")  # Strike price\n",
        "G.add_node(\"T\", label=\"T (Time to Expiry)\", color=\"lightgray\")  # Time to expiry\n",
        "G.add_node(\"sigma\", label=\"σ (Volatility)\", color=\"lightgray\")  # Volatility\n",
        "\n",
        "# Intermediate computations\n",
        "# Compute d1\n",
        "G.add_node(\"v1\", label=\"log(F / K)\", color=\"white\")\n",
        "G.add_edge(\"F\", \"v1\")\n",
        "G.add_edge(\"K\", \"v1\")\n",
        "\n",
        "G.add_node(\"v2\", label=\"(1/2) * σ^2 * T\", color=\"white\")\n",
        "G.add_edge(\"sigma\", \"v2\")\n",
        "G.add_edge(\"T\", \"v2\")\n",
        "\n",
        "G.add_node(\"v3\", label=\"log(F / K) + (1/2) * σ^2 * T\", color=\"white\")\n",
        "G.add_edge(\"v1\", \"v3\")\n",
        "G.add_edge(\"v2\", \"v3\")\n",
        "\n",
        "G.add_node(\"v4\", label=\"σ * sqrt(T)\", color=\"white\")\n",
        "G.add_edge(\"sigma\", \"v4\")\n",
        "G.add_edge(\"T\", \"v4\")\n",
        "\n",
        "G.add_node(\"d1\", label=\"d1 = [log(F / K) + (1/2) * σ^2 * T] / (σ * sqrt(T))\", color=\"white\")\n",
        "G.add_edge(\"v3\", \"d1\")\n",
        "G.add_edge(\"v4\", \"d1\")\n",
        "\n",
        "# Compute d2\n",
        "G.add_node(\"d2\", label=\"d2 = d1 - σ * sqrt(T)\", color=\"white\")\n",
        "G.add_edge(\"d1\", \"d2\")\n",
        "G.add_edge(\"v4\", \"d2\")\n",
        "\n",
        "# Normal CDF computations\n",
        "G.add_node(\"N(d1)\", label=\"N(d1)\", color=\"white\")\n",
        "G.add_edge(\"d1\", \"N(d1)\")\n",
        "\n",
        "G.add_node(\"N(d2)\", label=\"N(d2)\", color=\"white\")\n",
        "G.add_edge(\"d2\", \"N(d2)\")\n",
        "\n",
        "# Final output (call option price)\n",
        "G.add_node(\"C\", label=\"C = exp(-rT) * [F * N(d1) - K * N(d2)]\", color=\"lightblue\")\n",
        "G.add_edge(\"F\", \"C\")\n",
        "G.add_edge(\"K\", \"C\")\n",
        "G.add_edge(\"N(d1)\", \"C\")\n",
        "G.add_edge(\"N(d2)\", \"C\")\n",
        "G.add_edge(\"T\", \"C\")\n",
        "\n",
        "# Draw the graph\n",
        "pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n",
        "colors = [G.nodes[n].get(\"color\", \"white\") for n in G.nodes()]\n",
        "labels = nx.get_node_attributes(G, \"label\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "nx.draw(G, pos, with_labels=True, labels=labels, node_color=colors, node_size=3000, font_size=8, font_color=\"black\")\n",
        "plt.title(\"Computational Graph for Black Formula (Call Option)\")\n",
        "\n",
        "# Save as PDF\n",
        "output_path = \"Black_Formula_Call_Option_Graph01.pdf\"\n",
        "plt.savefig(output_path, format=\"pdf\", bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "output_path\n"
      ],
      "metadata": {
        "id": "Ns3dtSCQi1UZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the computational graph for the given function\n",
        "G = nx.DiGraph()\n",
        "\n",
        "# Inputs\n",
        "G.add_node(\"y\", label=\"y\", color=\"lightgray\")  # Observation\n",
        "G.add_node(\"mu\", label=\"μ\", color=\"lightgray\")  # Mean\n",
        "G.add_node(\"sigma\", label=\"σ\", color=\"lightgray\")  # Standard deviation\n",
        "\n",
        "# Intermediate computations\n",
        "G.add_node(\"v1\", label=\"y - μ\", color=\"white\")  # Difference\n",
        "G.add_edge(\"y\", \"v1\") # Changed g to G\n",
        "G.add_edge(\"mu\", \"v1\")\n",
        "\n",
        "G.add_node(\"v2\", label=\"(y - μ) / σ\", color=\"white\")  # Division\n",
        "G.add_edge(\"v1\", \"v2\") # Changed g to G\n",
        "G.add_edge(\"sigma\", \"v2\")\n",
        "\n",
        "G.add_node(\"v3\", label=\"((y - μ) / σ)^2\", color=\"white\")  # Square\n",
        "G.add_edge(\"v2\", \"v3\") # Changed g to G\n",
        "\n",
        "G.add_node(\"v4\", label=\"-1/2 * ((y - μ) / σ)^2\", color=\"white\")  # Multiply by -1/2\n",
        "G.add_edge(\"v3\", \"v4\") # Changed g to G\n",
        "\n",
        "G.add_node(\"v5\", label=\"log(σ)\", color=\"white\")  # Log of sigma\n",
        "G.add_edge(\"sigma\", \"v5\") # Changed g to G\n",
        "\n",
        "G.add_node(\"v6\", label=\"- log(σ)\", color=\"white\")  # Negative log of sigma\n",
        "G.add_edge(\"v5\", \"v6\") # Changed g to G\n",
        "\n",
        "G.add_node(\"v7\", label=\"-1/2 * log(2π)\", color=\"white\")  # Constant term\n",
        "\n",
        "# Final output\n",
        "G.add_node(\"f\", label=\"f(y, μ, σ)\", color=\"lightblue\")\n",
        "G.add_edge(\"v4\", \"f\") # Changed g to G\n",
        "G.add_edge(\"v6\", \"f\") # Changed g to G\n",
        "G.add_edge(\"v7\", \"f\") # Changed g to G\n",
        "\n",
        "# Draw the graph\n",
        "pos = nx.nx_agraph.graphviz_layout(G, prog=\"dot\")\n",
        "colors = [G.nodes[n].get(\"color\", \"white\") for n in G.nodes()]\n",
        "labels = nx.get_node_attributes(G, \"label\")\n",
        "\n",
        "plt.figure(figsize=(12, 8))\n",
        "nx.draw(G, pos, with_labels=True, labels=labels, node_color=colors, node_size=3000, font_size=8, font_color=\"black\")\n",
        "plt.title(\"Computational Graph for f(y, μ, σ)\")\n",
        "\n",
        "# Save as PDF\n",
        "output_path = \"Function_Computational_Graph.pdf\"\n",
        "plt.savefig(output_path, format=\"pdf\", bbox_inches=\"tight\")\n",
        "plt.close()\n",
        "\n",
        "output_path"
      ],
      "metadata": {
        "id": "spgcdtRdi2ON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zZ6nK0XXmQt8"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}